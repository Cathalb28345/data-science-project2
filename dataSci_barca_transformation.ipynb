{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing and Machine Learning Tutorial using Jupyter Notebook for data science assessment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Before you begin</h2>\n",
    "<p>First you are required to have both python and jupyter notebook installed on your machine and running . It is recommanded to use linux by the devlopers but using widows worths fine with only some small issues.</p>\n",
    "\n",
    "<p>Install python for Windows <a href=\"https://www.ics.uci.edu/~pattis/common/handouts/pythoneclipsejava/python.html\">tutorial</a></p>\n",
    "\n",
    "\n",
    "<p>Install Jupyter Notebook for Linux <a href=\"https://www.digitalocean.com/community/tutorials/how-to-set-up-jupyter-notebook-with-python-3-on-ubuntu-18-04\">tutorial</a></p>\n",
    "\n",
    "\n",
    "<p>Install Anaconda for Windows <a href=\"https://docs.anaconda.com/anaconda/install/windows/\">Anaconda tutorial</a></p>\n",
    "\n",
    "<p>Install Jupyter Notebook for Windows <a href=\"https://jupyter.readthedocs.io/en/latest/install.html\">Jupyter Notebook for Windows tutorial</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> What will we be discussing?</h1>\n",
    "<ul>\n",
    "   <li> <h2> What is Data Preprocessing?</h2>\n",
    "    <p>\n",
    "        Data preprocessing is a data mining technique that involves transforming raw data into an understandable format. Real world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors. Data preprocessing is a proven method of resolving such issues. Data preprocessing prepares raw data for further processing.\n",
    "        \n",
    "        \n",
    "Steps required<br>\n",
    "Step 1 : Import Libraries\n",
    "\n",
    "Step 2 : Import the Dataset\n",
    "\n",
    "Step 3 : Checking for missing data\n",
    "\n",
    "Step 4 : Splitting the data-set into Training and Test Set\n",
    "\n",
    "Step 5 : Feature Scaling\n",
    "\n",
    "        \n",
    " \n",
    "   </li>\n",
    "        \n",
    "</p></li>\n",
    "<li>\n",
    "     <h2> What is Machine learning?</h2>\n",
    "    <p>Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to effectively perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.</p> \n",
    "   </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing the required Libraries</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must use these commands atleast once to install the libraries so they can be imported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install plotly\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to import the libraries so they can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt  # linear algebr\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import cufflinks as cf\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "\n",
    "offline.init_notebook_mode()\n",
    "from plotly import tools\n",
    "import plotly.tools as tls\n",
    "\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os  # accessing directory structure\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt  # plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Numpy</h3>\n",
    "NumPy is the fundamental package for scientific computing with Python.\n",
    "\n",
    "<h3>Pandas</h3>\n",
    "Pandas is for data manipulation and analysis.\n",
    "\n",
    "<h3>folium</h3>\n",
    "Makes it easy to visualize data thatâ€™s been manipulated in Python on an interactive leaflet map. It enables both the binding of data to a map for choropleth visualizations as well as passing rich vector/raster/HTML visualizations as markers on the map.\n",
    "<h3>Matplotlib</h3>\n",
    "Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hard copy formats and interactive environments across platforms.\n",
    "\n",
    "<h3>Seaborn</h3>\n",
    "Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "\n",
    "<h2>Check to see the datasets are pulled in if they appear they are loaded in</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"C:/Users/catha/barcelona-data-sets/input\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import the Datasets and begin preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRowsRead = None\n",
    "accidents_df = pd.read_csv('C:/Users/catha/barcelona-data-sets/input/accidents_2017.csv', delimiter=',', nrows = nRowsRead)\n",
    "accidents_df.dataframeName = 'accidents_2017.csv'\n",
    "nRow, nCol = accidents_df.shape\n",
    "\n",
    "# Drop a row by condition\n",
    "accidents_df= accidents_df[accidents_df.District_Name != 'Unknown'] # strip any unknown string values\n",
    "accidents_df= accidents_df[accidents_df.Neighborhood_Name  != 'Unknown']  # strip any unknown string values\n",
    "\n",
    "print(f'There are {nRow} rows and {nCol} columns in accidents')\n",
    "\n",
    "nRowsRead = None \n",
    "births_df  = pd.read_csv('C:/Users/catha/barcelona-data-sets/input/births.csv', delimiter=',', nrows = nRowsRead)\n",
    "births_df .dataframeName = 'births.csv'\n",
    "nRow, nCol = births_df .shape\n",
    "\n",
    "print(f'There are {nRow} rows and {nCol} columns in births')\n",
    "\n",
    "nRowsRead = None \n",
    "population_df  = pd.read_csv('C:/Users/catha/barcelona-data-sets/input/population.csv', delimiter=',', nrows = nRowsRead)\n",
    "population_df .dataframeName = 'population.csv'\n",
    "nRow, nCol = population_df .shape\n",
    "print(f'There are {nRow} rows and {nCol} columns in population_df')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Some sample birth data for boys</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Some sample birth data for girls </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Birth data in comparison for the year 2017 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_births_df = births_df.loc[births_df['Year'] == 2017].groupby(['Gender'])['Number'].sum()\n",
    "\n",
    "trace = go.Pie(labels = temp_births_df.index,\n",
    "               values = temp_births_df.values,\n",
    "               marker = dict(colors=['#E53916','#2067AD'], line = dict(color='#FFFFFF', width=2.5))\n",
    "              )\n",
    "\n",
    "data = [trace]\n",
    "layout = go.Layout(title=\"Gender-Wise births for Year-2017\")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Population data in comparison for the year 2017 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_population_df = population_df.loc[population_df['Year'] == 2017].groupby(['Gender'])['Number'].sum()\n",
    "\n",
    "trace = go.Pie(labels=temp_population_df.index,\n",
    "               values=temp_population_df.values,\n",
    "               marker=dict(colors=['#E53916', '#2067AD'], line=dict(color='#FFFFFF', width=2.5))\n",
    "               )\n",
    "\n",
    "data = [trace]\n",
    "layout = go.Layout(title=\"Gender-Wise Distribution for Year-2017\")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>My data set is combined between birth records and population records and this is what i will be basing my data on they are as follows: </h3>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Birth Dataset </li>\n",
    "    <li>Population Dataset </li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Checking for missing data in birth data set</h2>\n",
    "<p>this should show two entries that i ahve placed in it as the data was mostly corrrect </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_df.loc[births_df['Gender'] == 'Unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the sixth column you will notice two entries that are intentially incorrect, I will run a method to check for other errors in the data soon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Displaying some population data in population data set</h2>\n",
    "<p>This will display the current status of the population by the indivial districts </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dist_df = population_df.loc[population_df['Year'] == 2017].groupby(['District_Name'])['Number'].sum()\n",
    "\n",
    "trace0 = go.Bar(x=population_dist_df.index,\n",
    "                y=population_dist_df.values,\n",
    "                marker=dict(color=list(population_dist_df.values),\n",
    "                            colorscale='Reds'),\n",
    "                )\n",
    "\n",
    "data = [trace0]\n",
    "layout = go.Layout(xaxis=dict(tickangle=-30),\n",
    "                   title=\"District-Wise Distribution of population (Year 2017)\",\n",
    "                   )\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Checking for accidents in the city and there frequency of occurence </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "barcelona_coordinates = [41.406141, 2.168594]\n",
    "\n",
    "map_accidents = folium.Map(location=barcelona_coordinates, tiles='CartoDB Dark_Matter', zoom_start=13)\n",
    "\n",
    "lat_long_df = accidents_df[['Latitude','Longitude']]\n",
    "\n",
    "lat_long = [[row['Latitude'],row['Longitude']] for index,row in lat_long_df.iterrows()]\n",
    "\n",
    "map_accidents.add_children(plugins.HeatMap(lat_long))\n",
    "\n",
    "HeatMap(lat_long, min_opacity=0.5, radius=15).add_to(map_accidents)\n",
    "map_accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Splitting the data-set into Training and Test Set for Machine Learning</h2>\n",
    "In any Machine Learning model we are going to split dataset into two different sets. The Training setet and the Test set. \n",
    "\n",
    "Using linear Regression  we will attempt to predict the future values for the births data set to try predict the birth rate in boys and girls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
